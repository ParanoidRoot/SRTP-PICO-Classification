10/27/2019 12:51:18 - INFO - root -   {'run_text': 'PICO-Classification-By-Bert', 'train_size': -1, 'val_size': -1, 'log_path': WindowsPath('logs/combined'), 'full_data_dir': WindowsPath('data/combined'), 'data_dir': WindowsPath('data/combined'), 'task_name': 'PICO-Classification', 'no_cuda': False, 'bert_model': WindowsPath('pretrained'), 'output_dir': WindowsPath('models/combined/output'), 'max_seq_length': 60, 'do_train': True, 'do_eval': True, 'do_lower_case': True, 'train_batch_size': 8, 'eval_batch_size': 16, 'learning_rate': 5e-05, 'num_train_epochs': 20, 'warmup_proportion': 0.0, 'local_rank': -1, 'seed': 42, 'gradient_accumulation_steps': 1, 'optimize_on_cpu': False, 'fp16': True, 'fp16_opt_level': 'O1', 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'max_steps': -1, 'warmup_steps': 500, 'logging_steps': 50, 'eval_all_checkpoints': True, 'overwrite_output_dir': True, 'overwrite_cache': False, 'loss_scale': 128, 'model_name': 'bert-base-uncased', 'model_type': 'bert', 'multi_gpu': False}
10/27/2019 12:51:18 - INFO - transformers.tokenization_utils -   Model name 'pretrained' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'pretrained' is a path or url to a directory containing tokenizer files.
10/27/2019 12:51:18 - INFO - transformers.tokenization_utils -   Didn't find file pretrained\added_tokens.json. We won't load it.
10/27/2019 12:51:18 - INFO - transformers.tokenization_utils -   Didn't find file pretrained\special_tokens_map.json. We won't load it.
10/27/2019 12:51:18 - INFO - transformers.tokenization_utils -   Didn't find file pretrained\tokenizer_config.json. We won't load it.
10/27/2019 12:51:18 - INFO - transformers.tokenization_utils -   loading file pretrained\vocab.txt
10/27/2019 12:51:18 - INFO - transformers.tokenization_utils -   loading file None
10/27/2019 12:51:18 - INFO - transformers.tokenization_utils -   loading file None
10/27/2019 12:51:18 - INFO - transformers.tokenization_utils -   loading file None
10/27/2019 12:51:23 - INFO - root -   Writing example 0 of 3202
10/27/2019 12:51:31 - INFO - root -   Saving features into cached file data\combined\cache\cached_bert_train_multi_label_60
10/27/2019 12:51:34 - INFO - root -   Writing example 0 of 640
10/27/2019 12:51:36 - INFO - root -   Saving features into cached file data\combined\cache\cached_bert_dev_multi_label_60
10/27/2019 12:51:37 - INFO - pytorch_transformers.modeling_utils -   loading configuration file pretrained\config.json
10/27/2019 12:51:37 - INFO - pytorch_transformers.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 20,
  "output_attentions": false,
  "output_hidden_states": false,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

10/27/2019 12:51:37 - INFO - pytorch_transformers.modeling_utils -   loading weights file pretrained\pytorch_model.bin
10/27/2019 12:51:43 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
10/27/2019 12:51:43 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
10/27/2019 12:51:48 - INFO - root -   ***** Running training *****
10/27/2019 12:51:48 - INFO - root -     Num examples = 3202
10/27/2019 12:51:48 - INFO - root -     Num Epochs = 20
10/27/2019 12:51:48 - INFO - root -     Total train batch size (w. parallel, distributed & accumulation) = 8
10/27/2019 12:51:48 - INFO - root -     Gradient Accumulation steps = 1
10/27/2019 12:51:48 - INFO - root -     Total optimization steps = 8020
10/27/2019 12:55:57 - INFO - root -   Running evaluation
10/27/2019 12:55:57 - INFO - root -     Num examples = 640
10/27/2019 12:55:57 - INFO - root -     Batch size = 16
10/27/2019 12:56:02 - INFO - root -   eval_loss after epoch 1: 0.5362421691417694: 
10/27/2019 12:56:02 - INFO - root -   eval_accuracy_thresh after epoch 1: 0.7879687547683716: 
10/27/2019 12:56:02 - INFO - root -   eval_roc_auc after epoch 1: 0.5126766056717941: 
10/27/2019 12:56:02 - INFO - root -   eval_fbeta after epoch 1: 0.106500543653965: 
10/27/2019 12:56:02 - INFO - root -   eval_accuracy_multilabel after epoch 1: 0.0078125: 
10/27/2019 12:56:02 - INFO - root -   lr after epoch 1: 4.0100000000000006e-05
10/27/2019 12:56:02 - INFO - root -   train_loss after epoch 1: 0.6362150587940454
10/27/2019 12:56:02 - INFO - root -   

10/27/2019 13:00:05 - INFO - root -   Running evaluation
10/27/2019 13:00:05 - INFO - root -     Num examples = 640
10/27/2019 13:00:05 - INFO - root -     Batch size = 16
10/27/2019 13:00:10 - INFO - root -   eval_loss after epoch 2: 0.34249819070100784: 
10/27/2019 13:00:10 - INFO - root -   eval_accuracy_thresh after epoch 2: 0.9742187261581421: 
10/27/2019 13:00:10 - INFO - root -   eval_roc_auc after epoch 2: 0.6404063084736701: 
10/27/2019 13:00:10 - INFO - root -   eval_fbeta after epoch 2: 0.10221081227064133: 
10/27/2019 13:00:10 - INFO - root -   eval_accuracy_multilabel after epoch 2: 0.0078125: 
10/27/2019 13:00:10 - INFO - root -   lr after epoch 2: 4.980129362112663e-05
10/27/2019 13:00:10 - INFO - root -   train_loss after epoch 2: 0.43393183185572637
10/27/2019 13:00:10 - INFO - root -   

10/27/2019 13:03:59 - INFO - root -   Running evaluation
10/27/2019 13:03:59 - INFO - root -     Num examples = 640
10/27/2019 13:03:59 - INFO - root -     Batch size = 16
10/27/2019 13:04:04 - INFO - root -   eval_loss after epoch 3: 0.24551421515643596: 
10/27/2019 13:04:04 - INFO - root -   eval_accuracy_thresh after epoch 3: 0.9742187261581421: 
10/27/2019 13:04:04 - INFO - root -   eval_roc_auc after epoch 3: 0.7138209278024835: 
10/27/2019 13:04:04 - INFO - root -   eval_fbeta after epoch 3: 0.0: 
10/27/2019 13:04:04 - INFO - root -   eval_accuracy_multilabel after epoch 3: 0.228125: 
10/27/2019 13:04:04 - INFO - root -   lr after epoch 3: 4.892956358060328e-05
10/27/2019 13:04:04 - INFO - root -   train_loss after epoch 3: 0.2984898433349376
10/27/2019 13:04:04 - INFO - root -   

10/27/2019 13:07:51 - INFO - root -   Running evaluation
10/27/2019 13:07:51 - INFO - root -     Num examples = 640
10/27/2019 13:07:51 - INFO - root -     Batch size = 16
10/27/2019 13:07:56 - INFO - root -   eval_loss after epoch 4: 0.18856090046465396: 
10/27/2019 13:07:56 - INFO - root -   eval_accuracy_thresh after epoch 4: 0.9742187261581421: 
10/27/2019 13:07:56 - INFO - root -   eval_roc_auc after epoch 4: 0.7463050715656971: 
10/27/2019 13:07:56 - INFO - root -   eval_fbeta after epoch 4: 0.0: 
10/27/2019 13:07:56 - INFO - root -   eval_accuracy_multilabel after epoch 4: 0.1015625: 
10/27/2019 13:07:56 - INFO - root -   lr after epoch 4: 4.738783836932108e-05
10/27/2019 13:07:56 - INFO - root -   train_loss after epoch 4: 0.222212565547213
10/27/2019 13:07:56 - INFO - root -   

10/27/2019 13:11:42 - INFO - root -   Running evaluation
10/27/2019 13:11:42 - INFO - root -     Num examples = 640
10/27/2019 13:11:42 - INFO - root -     Batch size = 16
10/27/2019 13:11:47 - INFO - root -   eval_loss after epoch 5: 0.15278000403195618: 
10/27/2019 13:11:47 - INFO - root -   eval_accuracy_thresh after epoch 5: 0.9742187261581421: 
10/27/2019 13:11:47 - INFO - root -   eval_roc_auc after epoch 5: 0.7661236664965615: 
10/27/2019 13:11:47 - INFO - root -   eval_fbeta after epoch 5: 0.0: 
10/27/2019 13:11:47 - INFO - root -   eval_accuracy_multilabel after epoch 5: 0.1359375: 
10/27/2019 13:11:47 - INFO - root -   lr after epoch 5: 4.5219284192243064e-05
10/27/2019 13:11:47 - INFO - root -   train_loss after epoch 5: 0.17469335732020047
10/27/2019 13:11:47 - INFO - root -   

10/27/2019 13:15:31 - INFO - root -   Running evaluation
10/27/2019 13:15:31 - INFO - root -     Num examples = 640
10/27/2019 13:15:31 - INFO - root -     Batch size = 16
10/27/2019 13:15:36 - INFO - root -   eval_loss after epoch 6: 0.13056373372673988: 
10/27/2019 13:15:36 - INFO - root -   eval_accuracy_thresh after epoch 6: 0.9742187261581421: 
10/27/2019 13:15:36 - INFO - root -   eval_roc_auc after epoch 6: 0.785578965274234: 
10/27/2019 13:15:36 - INFO - root -   eval_fbeta after epoch 6: 0.0: 
10/27/2019 13:15:37 - INFO - root -   eval_accuracy_multilabel after epoch 6: 0.19375: 
10/27/2019 13:15:37 - INFO - root -   lr after epoch 6: 4.248461761117685e-05
10/27/2019 13:15:37 - INFO - root -   train_loss after epoch 6: 0.14483922357645415
10/27/2019 13:15:37 - INFO - root -   

10/27/2019 13:19:21 - INFO - root -   Running evaluation
10/27/2019 13:19:21 - INFO - root -     Num examples = 640
10/27/2019 13:19:21 - INFO - root -     Batch size = 16
10/27/2019 13:19:26 - INFO - root -   eval_loss after epoch 7: 0.11670158430933952: 
10/27/2019 13:19:26 - INFO - root -   eval_accuracy_thresh after epoch 7: 0.9742187261581421: 
10/27/2019 13:19:26 - INFO - root -   eval_roc_auc after epoch 7: 0.7991141163033705: 
10/27/2019 13:19:26 - INFO - root -   eval_fbeta after epoch 7: 0.0: 
10/27/2019 13:19:26 - INFO - root -   eval_accuracy_multilabel after epoch 7: 0.196875: 
10/27/2019 13:19:26 - INFO - root -   lr after epoch 7: 3.926040556378423e-05
10/27/2019 13:19:26 - INFO - root -   train_loss after epoch 7: 0.12654161245151055
10/27/2019 13:19:26 - INFO - root -   

10/27/2019 13:23:12 - INFO - root -   Running evaluation
10/27/2019 13:23:12 - INFO - root -     Num examples = 640
10/27/2019 13:23:12 - INFO - root -     Batch size = 16
10/27/2019 13:23:17 - INFO - root -   eval_loss after epoch 8: 0.1076618186198175: 
10/27/2019 13:23:17 - INFO - root -   eval_accuracy_thresh after epoch 8: 0.9742187261581421: 
10/27/2019 13:23:17 - INFO - root -   eval_roc_auc after epoch 8: 0.8153132366163641: 
10/27/2019 13:23:17 - INFO - root -   eval_fbeta after epoch 8: 0.0062500000931322575: 
10/27/2019 13:23:17 - INFO - root -   eval_accuracy_multilabel after epoch 8: 0.2015625: 
10/27/2019 13:23:17 - INFO - root -   lr after epoch 8: 3.56369215936666e-05
10/27/2019 13:23:17 - INFO - root -   train_loss after epoch 8: 0.11506684294476771
10/27/2019 13:23:17 - INFO - root -   

10/27/2019 13:27:02 - INFO - root -   Running evaluation
10/27/2019 13:27:02 - INFO - root -     Num examples = 640
10/27/2019 13:27:02 - INFO - root -     Batch size = 16
10/27/2019 13:27:07 - INFO - root -   eval_loss after epoch 9: 0.10188546953722835: 
10/27/2019 13:27:07 - INFO - root -   eval_accuracy_thresh after epoch 9: 0.9742187261581421: 
10/27/2019 13:27:07 - INFO - root -   eval_roc_auc after epoch 9: 0.8186212971738233: 
10/27/2019 13:27:07 - INFO - root -   eval_fbeta after epoch 9: 0.05937499925494194: 
10/27/2019 13:27:07 - INFO - root -   eval_accuracy_multilabel after epoch 9: 0.2015625: 
10/27/2019 13:27:07 - INFO - root -   lr after epoch 9: 3.171561831416239e-05
10/27/2019 13:27:07 - INFO - root -   train_loss after epoch 9: 0.10756151301976749
10/27/2019 13:27:07 - INFO - root -   

10/27/2019 13:30:50 - INFO - root -   Running evaluation
10/27/2019 13:30:50 - INFO - root -     Num examples = 640
10/27/2019 13:30:50 - INFO - root -     Batch size = 16
10/27/2019 13:30:55 - INFO - root -   eval_loss after epoch 10: 0.09765409445390105: 
10/27/2019 13:30:55 - INFO - root -   eval_accuracy_thresh after epoch 10: 0.9746874570846558: 
10/27/2019 13:30:55 - INFO - root -   eval_roc_auc after epoch 10: 0.8266907244052393: 
10/27/2019 13:30:55 - INFO - root -   eval_fbeta after epoch 10: 0.08281250298023224: 
10/27/2019 13:30:55 - INFO - root -   eval_accuracy_multilabel after epoch 10: 0.225: 
10/27/2019 13:30:55 - INFO - root -   lr after epoch 10: 2.7606286873426045e-05
10/27/2019 13:30:55 - INFO - root -   train_loss after epoch 10: 0.10294632138939867
10/27/2019 13:30:55 - INFO - root -   

10/27/2019 13:34:41 - INFO - root -   Running evaluation
10/27/2019 13:34:41 - INFO - root -     Num examples = 640
10/27/2019 13:34:41 - INFO - root -     Batch size = 16
10/27/2019 13:34:46 - INFO - root -   eval_loss after epoch 11: 0.09526646519079804: 
10/27/2019 13:34:46 - INFO - root -   eval_accuracy_thresh after epoch 11: 0.9755468368530273: 
10/27/2019 13:34:46 - INFO - root -   eval_roc_auc after epoch 11: 0.8380848582051469: 
10/27/2019 13:34:46 - INFO - root -   eval_fbeta after epoch 11: 0.13993056118488312: 
10/27/2019 13:34:46 - INFO - root -   eval_accuracy_multilabel after epoch 11: 0.23125: 
10/27/2019 13:34:46 - INFO - root -   lr after epoch 11: 2.3423982951895147e-05
10/27/2019 13:34:46 - INFO - root -   train_loss after epoch 11: 0.09920527914218474
10/27/2019 13:34:46 - INFO - root -   

10/27/2019 13:38:32 - INFO - root -   Running evaluation
10/27/2019 13:38:32 - INFO - root -     Num examples = 640
10/27/2019 13:38:32 - INFO - root -     Batch size = 16
10/27/2019 13:38:37 - INFO - root -   eval_loss after epoch 12: 0.09204884264618159: 
10/27/2019 13:38:37 - INFO - root -   eval_accuracy_thresh after epoch 12: 0.9753124713897705: 
10/27/2019 13:38:37 - INFO - root -   eval_roc_auc after epoch 12: 0.8475498772812325: 
10/27/2019 13:38:37 - INFO - root -   eval_fbeta after epoch 12: 0.14461806416511536: 
10/27/2019 13:38:37 - INFO - root -   eval_accuracy_multilabel after epoch 12: 0.2375: 
10/27/2019 13:38:37 - INFO - root -   lr after epoch 12: 1.928580536002785e-05
10/27/2019 13:38:37 - INFO - root -   train_loss after epoch 12: 0.09641295011872959
10/27/2019 13:38:37 - INFO - root -   

10/27/2019 13:42:23 - INFO - root -   Running evaluation
10/27/2019 13:42:23 - INFO - root -     Num examples = 640
10/27/2019 13:42:23 - INFO - root -     Batch size = 16
10/27/2019 13:42:28 - INFO - root -   eval_loss after epoch 13: 0.09096559723839164: 
10/27/2019 13:42:28 - INFO - root -   eval_accuracy_thresh after epoch 13: 0.9755468368530273: 
10/27/2019 13:42:28 - INFO - root -   eval_roc_auc after epoch 13: 0.8468407815119924: 
10/27/2019 13:42:28 - INFO - root -   eval_fbeta after epoch 13: 0.17291666567325592: 
10/27/2019 13:42:28 - INFO - root -   eval_accuracy_multilabel after epoch 13: 0.2375: 
10/27/2019 13:42:28 - INFO - root -   lr after epoch 13: 1.530761743118394e-05
10/27/2019 13:42:28 - INFO - root -   train_loss after epoch 13: 0.0942823738463576
10/27/2019 13:42:28 - INFO - root -   

10/27/2019 13:46:29 - INFO - root -   Running evaluation
10/27/2019 13:46:29 - INFO - root -     Num examples = 640
10/27/2019 13:46:29 - INFO - root -     Batch size = 16
10/27/2019 13:46:34 - INFO - root -   eval_loss after epoch 14: 0.08939351243898272: 
10/27/2019 13:46:34 - INFO - root -   eval_accuracy_thresh after epoch 14: 0.9759374856948853: 
10/27/2019 13:46:34 - INFO - root -   eval_roc_auc after epoch 14: 0.858209764039756: 
10/27/2019 13:46:34 - INFO - root -   eval_fbeta after epoch 14: 0.16024306416511536: 
10/27/2019 13:46:34 - INFO - root -   eval_accuracy_multilabel after epoch 14: 0.240625: 
10/27/2019 13:46:34 - INFO - root -   lr after epoch 14: 1.1600803006181024e-05
10/27/2019 13:46:34 - INFO - root -   train_loss after epoch 14: 0.09276020006645945
10/27/2019 13:46:34 - INFO - root -   

10/27/2019 13:50:41 - INFO - root -   Running evaluation
10/27/2019 13:50:41 - INFO - root -     Num examples = 640
10/27/2019 13:50:41 - INFO - root -     Batch size = 16
10/27/2019 13:50:46 - INFO - root -   eval_loss after epoch 15: 0.08916332731023431: 
10/27/2019 13:50:46 - INFO - root -   eval_accuracy_thresh after epoch 15: 0.9757812023162842: 
10/27/2019 13:50:46 - INFO - root -   eval_roc_auc after epoch 15: 0.8630292094967316: 
10/27/2019 13:50:46 - INFO - root -   eval_fbeta after epoch 15: 0.1649305671453476: 
10/27/2019 13:50:46 - INFO - root -   eval_accuracy_multilabel after epoch 15: 0.234375: 
10/27/2019 13:50:46 - INFO - root -   lr after epoch 15: 8.269147837537549e-06
10/27/2019 13:50:46 - INFO - root -   train_loss after epoch 15: 0.09173165166987446
10/27/2019 13:50:46 - INFO - root -   

10/27/2019 13:54:44 - INFO - root -   Running evaluation
10/27/2019 13:54:44 - INFO - root -     Num examples = 640
10/27/2019 13:54:44 - INFO - root -     Batch size = 16
10/27/2019 13:54:49 - INFO - root -   eval_loss after epoch 16: 0.08782766638323665: 
10/27/2019 13:54:49 - INFO - root -   eval_accuracy_thresh after epoch 16: 0.9763280749320984: 
10/27/2019 13:54:49 - INFO - root -   eval_roc_auc after epoch 16: 0.8649904012053171: 
10/27/2019 13:54:50 - INFO - root -   eval_fbeta after epoch 16: 0.16979166865348816: 
10/27/2019 13:54:50 - INFO - root -   eval_accuracy_multilabel after epoch 16: 0.240625: 
10/27/2019 13:54:50 - INFO - root -   lr after epoch 16: 5.4059337298341284e-06
10/27/2019 13:54:50 - INFO - root -   train_loss after epoch 16: 0.09115992547790903
10/27/2019 13:54:50 - INFO - root -   

10/27/2019 13:58:51 - INFO - root -   Running evaluation
10/27/2019 13:58:51 - INFO - root -     Num examples = 640
10/27/2019 13:58:51 - INFO - root -     Batch size = 16
10/27/2019 13:58:56 - INFO - root -   eval_loss after epoch 17: 0.08759861337020994: 
10/27/2019 13:58:56 - INFO - root -   eval_accuracy_thresh after epoch 17: 0.9760156273841858: 
10/27/2019 13:58:56 - INFO - root -   eval_roc_auc after epoch 17: 0.8669720055405701: 
10/27/2019 13:58:56 - INFO - root -   eval_fbeta after epoch 17: 0.16892361640930176: 
10/27/2019 13:58:56 - INFO - root -   eval_accuracy_multilabel after epoch 17: 0.2453125: 
10/27/2019 13:58:56 - INFO - root -   lr after epoch 17: 3.0913267763030164e-06
10/27/2019 13:58:56 - INFO - root -   train_loss after epoch 17: 0.09048372944654372
10/27/2019 13:58:56 - INFO - root -   

10/27/2019 14:02:46 - INFO - root -   Running evaluation
10/27/2019 14:02:46 - INFO - root -     Num examples = 640
10/27/2019 14:02:46 - INFO - root -     Batch size = 16
10/27/2019 14:02:51 - INFO - root -   eval_loss after epoch 18: 0.08757751481607556: 
10/27/2019 14:02:51 - INFO - root -   eval_accuracy_thresh after epoch 18: 0.9760937094688416: 
10/27/2019 14:02:51 - INFO - root -   eval_roc_auc after epoch 18: 0.8665418823357878: 
10/27/2019 14:02:51 - INFO - root -   eval_fbeta after epoch 18: 0.16979166865348816: 
10/27/2019 14:02:51 - INFO - root -   eval_accuracy_multilabel after epoch 18: 0.24375: 
10/27/2019 14:02:51 - INFO - root -   lr after epoch 18: 1.3901328174622447e-06
10/27/2019 14:02:51 - INFO - root -   train_loss after epoch 18: 0.09033577962595031
10/27/2019 14:02:51 - INFO - root -   

10/27/2019 14:06:45 - INFO - root -   Running evaluation
10/27/2019 14:06:45 - INFO - root -     Num examples = 640
10/27/2019 14:06:45 - INFO - root -     Batch size = 16
10/27/2019 14:06:50 - INFO - root -   eval_loss after epoch 19: 0.08738803640007972: 
10/27/2019 14:06:50 - INFO - root -   eval_accuracy_thresh after epoch 19: 0.9761718511581421: 
10/27/2019 14:06:50 - INFO - root -   eval_roc_auc after epoch 19: 0.8676791572501277: 
10/27/2019 14:06:50 - INFO - root -   eval_fbeta after epoch 19: 0.16979166865348816: 
10/27/2019 14:06:50 - INFO - root -   eval_accuracy_multilabel after epoch 19: 0.2453125: 
10/27/2019 14:06:51 - INFO - root -   lr after epoch 19: 3.499829658938775e-07
10/27/2019 14:06:51 - INFO - root -   train_loss after epoch 19: 0.08997920227522713
10/27/2019 14:06:51 - INFO - root -   

10/27/2019 14:10:51 - INFO - root -   Running evaluation
10/27/2019 14:10:51 - INFO - root -     Num examples = 640
10/27/2019 14:10:51 - INFO - root -     Batch size = 16
10/27/2019 14:10:56 - INFO - root -   eval_loss after epoch 20: 0.08733861865475774: 
10/27/2019 14:10:56 - INFO - root -   eval_accuracy_thresh after epoch 20: 0.9761718511581421: 
10/27/2019 14:10:56 - INFO - root -   eval_roc_auc after epoch 20: 0.8676637262763968: 
10/27/2019 14:10:56 - INFO - root -   eval_fbeta after epoch 20: 0.16979166865348816: 
10/27/2019 14:10:56 - INFO - root -   eval_accuracy_multilabel after epoch 20: 0.2453125: 
10/27/2019 14:10:56 - INFO - root -   lr after epoch 20: 0.0
10/27/2019 14:10:56 - INFO - root -   train_loss after epoch 20: 0.09008404414664183
10/27/2019 14:10:56 - INFO - root -   

10/27/2019 14:10:56 - INFO - root -   Running evaluation
10/27/2019 14:10:56 - INFO - root -     Num examples = 640
10/27/2019 14:10:56 - INFO - root -     Batch size = 16
